version: 0.2

env:
  variables:
    S3_BUCKET: "wgithubbucket"
    CODEARTIFACT_DOMAIN: "zabalytics"
    CODEARTIFACT_REPO: "pypi"
    PACKAGE_NAME: "file-encoder"
    PACKAGE_VERSION: "0.1.0"

phases:
  install:
    runtime-versions:
      python: 3.13
    commands:
      - python -m pip install --upgrade pip
      - pip install -e ".[dev]"
      - pip install build setuptools wheel ruff pytest pytest-cov twine awscli

  pre_build:
    commands:
      - echo "Running lint..."
      - ruff check src/file_encoder

  build:
    commands:
      - echo "Running tests..."
      - export PYTHONPATH=$(pwd)/src
      - pytest -v --cov=file_encoder --cov-report=xml:coverage.xml --junitxml=pytest-report.xml
      - echo "Building wheel..."
      - python -m build

  post_build:
    commands:
      - echo "Listing dist directory..."
      - ls -l dist/
      - echo "Uploading wheel(s) to S3..."
      - for file in dist/*.whl; do
          if [ -f "$file" ]; then
            aws s3 cp "$file" s3://$S3_BUCKET/wheels/ --region $AWS_DEFAULT_REGION;
          fi
        done
      - echo "Publishing to CodeArtifact..."
      - export CODEARTIFACT_AUTH_TOKEN=$(aws codeartifact get-authorization-token \
          --domain $CODEARTIFACT_DOMAIN \
          --query authorizationToken --output text \
          --region $AWS_DEFAULT_REGION)
      - export CODEARTIFACT_REPO_URL=$(aws codeartifact get-repository-endpoint \
          --domain $CODEARTIFACT_DOMAIN \
          --repository $CODEARTIFACT_REPO \
          --format pypi \
          --query repositoryEndpoint --output text \
          --region $AWS_DEFAULT_REGION)
      - for file in dist/*.whl; do
          if [ -f "$file" ]; then
            twine upload --repository-url $CODEARTIFACT_REPO_URL \
              -u aws -p $CODEARTIFACT_AUTH_TOKEN "$file";
          fi
        done

artifacts:
  files:
    - coverage.xml
    - pytest-report.xml
    - dist/*.whl
